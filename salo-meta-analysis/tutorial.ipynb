{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-Analysis with NiMARE\n",
    "\n",
    "## What is NiMARE?\n",
    "\n",
    "![NiMARE banner](images/nimare_banner.png)\n",
    "\n",
    "[NiMARE](https://nimare.readthedocs.io/en/0.0.12/) is a Python library for performing neuroimaging meta-analyses and related analyses, like automated annotation and functional decoding. The goal of NiMARE is to centralize and standardize implementations of common meta-analytic tools, so that researchers can use whatever tool is most appropriate for a given research question.\n",
    "\n",
    "There are already a number of tools for neuroimaging meta-analysis:\n",
    "\n",
    "| <h2>Tool</h2> | <h2>Scope</h2> |\n",
    "| :------------ | :------------- |\n",
    "| <a href=\"https://brainmap.org\"><img src=\"images/brainmap_logo.png\" alt=\"BrainMap\" width=\"400\"/></a> | BrainMap includes a suite of applications for (1) searching its manually-annotated coordinate-based database, (2) adding studies to the database, and (3) running ALE meta-analyses. While search results can be extracted using its Sleuth app, access to the full database requires a collaborative use agreement. |\n",
    "| <a href=\"https://brainmap.org\"><img src=\"images/neurosynth_logo.png\" alt=\"Neurosynth\" width=\"200\"/></a> | Neurosynth provides (1) a large, automatically-extracted coordinate-based database, (2) a website for performing large-scale automated meta-analyses, and (3) a Python library for performing meta-analyses and functional decoding, mostly relying on a version of the MKDA algorithm. The Python library has been deprecated in favor of `NiMARE`. |\n",
    "| <a href=\"https://www.neurovault.org\"><img src=\"images/neurovault_logo.png\" alt=\"Neurovault\" width=\"200\"/></a> | Neurovault is a repository for sharing unthresholded statistical images, which can be used to search for images to use in image-based meta-analyses. Neurovault provides a tool for basic meta-analyses and an integration with Neurosynth's database for online functional decoding. |\n",
    "| <a href=\"https://www.sdmproject.com\"><img src=\"images/sdm_logo.png\" alt=\"SDM\" width=\"200\"/></a> | The Seed-based _d_ Mapping (SDM) app provides a graphical user interface and SPM toolbox for performing meta-analyses with the SDM algorithm, which supports a mix of coordinates and images. |\n",
    "| <a href=\"https://github.com/canlab/Canlab_MKDA_MetaAnalysis\"><img src=\"images/mkda_logo.png\" alt=\"MKDA\" width=\"200\"/></a> | The MATLAB-based MKDA toolbox includes functions for performing coordinate-based meta-analyses with the MKDA algorithm. |\n",
    "\n",
    "The majority of the above tools are (1) closed source, (2) based on graphical user interfaces, and/or (3) written in a programming language that is rarely used by neuroimagers, such as Java. \n",
    "\n",
    "In addition to these established tools, there are always interesting new methods that are described in journal articles, but which are never translated to a well-documented and supported implementation.\n",
    "\n",
    "NiMARE attempts to consolidate the different algorithms that are currently spread out across a range of tools (or which never make the jump from paper to tool), while still ensuring that the original tools and papers can be cited appropriately.\n",
    "\n",
    "## NiMARE's design philosophy\n",
    "\n",
    "NiMARE's API is designed to be similar to that of [`scikit-learn`](https://scikit-learn.org/stable/), in that most tools are custom classes. These classes follow the following basic structure:\n",
    "\n",
    "1. Initialize the class with general parameters\n",
    "```python\n",
    "cls = Class(param1, param2)\n",
    "```\n",
    "\n",
    "2. For Estimator classes, apply a `fit` method to a `Dataset` object to generate a `MetaResult` object\n",
    "```python\n",
    "result = cls.fit(dataset)\n",
    "```\n",
    "\n",
    "3. For Transformer classes, apply a `transform` method to an object to return a transformed version of that object\n",
    "\n",
    "    - An example transformer that accepts a `Dataset`:\n",
    "```python\n",
    "dataset = cls.transform(dataset)\n",
    "```\n",
    "    - A transformer that accepts a `MetaResult`:\n",
    "```python\n",
    "result = cls.transform(result)\n",
    "```\n",
    "\n",
    "## Stability and consistency\n",
    "\n",
    "NiMARE is currently in alpha development, so we appreciate any feedback or bug reports users can provide. Given its status, NiMARE's API may change in the future.\n",
    "\n",
    "Usage questions can be submitted to [NeuroStars with the 'nimare' tag](https://neurostars.org/tag/nimare), while bug reports and feature requests can be submitted to [NiMARE's issue tracker](https://github.com/neurostuff/NiMARE/issues)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals for this tutorial\n",
    "\n",
    "1. Compiling meta-analytic datasets\n",
    "1. Working with NiMARE meta-analytic datasets\n",
    "1. Searching large datasets\n",
    "1. Performing coordinate-based meta-analyses\n",
    "1. Performing image-based meta-analyses\n",
    "1. Performing functional decoding using Neurosynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages we'll need for this tutorial\n",
    "%matplotlib inline\n",
    "import json\n",
    "import logging\n",
    "import pprint\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting, reporting\n",
    "\n",
    "import nimare\n",
    "\n",
    "# Don't show debugging or info logs\n",
    "logging.getLogger().setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/jovyan/shared/connectivity/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting and preparing data for meta-analysis\n",
    "\n",
    "NiMARE relies on a specification for meta-analytic datasets named [NIMADS](https://github.com/neurostuff/NIMADS). Under NIMADS, meta-analytic datasets are stored as JSON files, with information about peak coordinates, _relative_ links to any unthresholded statistical images, metadata, annotations, and raw text.\n",
    "\n",
    "**NOTE**: NiMARE users generally do not need to create JSONs manually, so we won't go into that structure in this tutorial. Instead, users will typically have access to datasets stored in more established formats, like [Neurosynth](https://github.com/neurosynth/neurosynth-data) and [Sleuth](http://brainmap.org/sleuth/) files.\n",
    "\n",
    "NiMARE datasets typically come from one of three formats:\n",
    "\n",
    "1. Text files generated by BrainMap's Sleuth tool\n",
    "1. Large database files from Neurosynth and NeuroQuery\n",
    "1. NIMADS-format JSON files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sleuth text files\n",
    "\n",
    "BrainMap users search for papers in the Sleuth app, which can output a text file. This text file can be used by BrainMap's GingerALE tool, as well as by NiMARE.\n",
    "\n",
    "The example file we will use is from [Laird et al. (2015)](https://doi.org/10.1016/j.neuroimage.2015.06.044), which analyzed face paradigms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleuth_file = os.path.join(DATA_DIR, \"Laird2015_faces.txt\")\n",
    "\n",
    "with open(sleuth_file, \"r\") as fo:\n",
    "    contents = fo.readlines()\n",
    "\n",
    "print(\"\".join(contents[:40]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = nimare.io.convert_sleuth_to_dataset(sleuth_file)\n",
    "print(dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurosynth and NeuroQuery databases\n",
    "\n",
    "Neurosynth and NeuroQuery are very large databases of coordinates.\n",
    "\n",
    "NiMARE contains tools for downloading and converting these databases to NiMARE Datasets.\n",
    "\n",
    "```python\n",
    "from nimare import extract, io\n",
    "\n",
    "# Download the desired version of Neurosynth from GitHub.\n",
    "files = extract.fetch_neurosynth(\n",
    "    data_dir=DATA_DIR,\n",
    "    version=\"7\",\n",
    "    source=\"abstract\",\n",
    "    vocab=\"terms\",\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "# Select the appropriate set of files\n",
    "neurosynth_db = files[0]\n",
    "\n",
    "# Convert the set of files to a Dataset object\n",
    "neurosynth_dset = io.convert_neurosynth_to_dataset(\n",
    "    coordinates_file=neurosynth_db[\"coordinates\"],  # Peak coordinates\n",
    "    metadata_file=neurosynth_db[\"metadata\"],  # Study metadata\n",
    "    annotations_files=neurosynth_db[\"features\"],  # Terms extracted from abstracts and study-wise weights\n",
    ")\n",
    "\n",
    "# Reduce the Dataset to the first 500 studies for the tutorial\n",
    "neurosynth_dset = neurosynth_dset.slice(neurosynth_dset.ids[:500])\n",
    "\n",
    "# Save the Dataset to a file\n",
    "neurosynth_dset.save(os.path.join(DATA_DIR, \"neurosynth_dset.pkl.gz\"))\n",
    "```\n",
    "\n",
    "For this tutorial, we will use a pre-generated Dataset object containing the first 500 studies from the Neurosynth database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurosynth_dset = nimare.dataset.Dataset.load(os.path.join(DATA_DIR, \"neurosynth_dataset.pkl.gz\"))\n",
    "print(neurosynth_dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NIMADS JSON files\n",
    "\n",
    "We will start by loading a dataset in NIMADS format, because this particular dataset contains both coordinates and images. This dataset is created from [Collection 1425 on NeuroVault](https://identifiers.org/neurovault.collection:1425), which contains [NIDM-Results packs](http://nidm.nidash.org/specs/nidm-results_130.html) for 21 pain studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimads_file = os.path.join(DATA_DIR, \"nidm_pain_dset.json\")\n",
    "\n",
    "with open(nimads_file, \"r\") as fo:\n",
    "    contents = fo.readlines()\n",
    "\n",
    "print(\"\".join(contents[:80]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimads_dset = nimare.dataset.Dataset(nimads_file)\n",
    "\n",
    "# In addition to loading the NIMADS-format JSON file,\n",
    "# we need to download the associated statistical images from NeuroVault,\n",
    "# for which NiMARE has a useful function.\n",
    "nimads_dset_images_dir = nimare.extract.download_nidm_pain(data_dir=DATA_DIR)\n",
    "\n",
    "# We then notify the Dataset about the location of the images,\n",
    "# so that the *relative paths* in the Dataset can be used to determine *absolute paths*.\n",
    "nimads_dset.update_path(nimads_dset_images_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of NiMARE datasets\n",
    "\n",
    "In NiMARE, datasets are stored in a special `Dataset` class. The `Dataset` class stores most relevant information as properties.\n",
    "\n",
    "The full list of identifiers in the Dataset is located in `Dataset.ids`. Identifiers are composed of two parts- a study ID and a contrast ID. Within the Dataset, those two parts are separated with a `-`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nimads_dset.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most other information is stored in `pandas` DataFrames. The five DataFrame-based attributes are `Dataset.metadata`, `Dataset.coordinates`, `Dataset.images`, `Dataset.annotations`, and `Dataset.texts`.\n",
    "\n",
    "Each DataFrame contains at least three columns: `study_id`, `contrast_id`, and `id`, which is the combined `study_id` and `contrast_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimads_dset.coordinates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimads_dset.metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimads_dset.images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimads_dset.annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The faces Dataset doesn't have any annotations, but the Neurosynth one does\n",
    "neurosynth_dset.annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None of the example Datasets have texts\n",
    "nimads_dset.texts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other relevant attributes are `Dataset.masker` and `Dataset.space`.\n",
    "\n",
    "`Dataset.masker` is a [nilearn Masker object](https://nilearn.github.io/stable/manipulating_images/masker_objects.html#), which specifies the manner in which voxel-wise information like peak coordinates and statistical images are mapped into usable arrays. Most meta-analytic tools within NiMARE accept a `masker` argument, so the Dataset's masker can be overridden in most cases.\n",
    "\n",
    "`Dataset.space` is just a string describing the standard space and resolution in which data within the Dataset are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimads_dset.masker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimads_dset.space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets can also be saved to, and loaded from, binarized (pickled) files.\n",
    "\n",
    "We cannot save files on Binder, so here is the code we would use to save the pain Dataset:\n",
    "\n",
    "```python\n",
    "nimads_dset.save(\"pain_dataset.pkl.gz\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching large datasets\n",
    "\n",
    "The `Dataset` class contains multiple methods for selecting subsets of studies within the dataset.\n",
    "We will use the **Neurosynth** Dataset for this section.\n",
    "\n",
    "One common approach is to search by \"labels\" or \"terms\" that apply to studies. In Neurosynth, labels are derived from term frequency within abstracts.\n",
    "\n",
    "The `slice` method creates a reduced `Dataset` from a list of IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pain_ids = neurosynth_dset.get_studies_by_label(\"terms_abstract_tfidf__pain\", label_threshold=0.001)\n",
    "ns_pain_dset = neurosynth_dset.slice(pain_ids)\n",
    "print(ns_pain_dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A MACM (meta-analytic coactivation modeling) analysis is generally performed by running a meta-analysis on studies with a peak in a region of interest, so Dataset includes two methods for searching based on the locations of coordinates: `Dataset.get_studies_by_coordinate` and `Dataset.get_studies_by_mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphere_ids = neurosynth_dset.get_studies_by_coordinate(\n",
    "    [[24, -2, -20]],  # The XYZ coordinates to search. There can be more than one.\n",
    "    r=6,  # The radius around the coordinates in which to search.\n",
    ")\n",
    "sphere_dset = neurosynth_dset.slice(sphere_ids)\n",
    "print(sphere_dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running meta-analyses\n",
    "\n",
    "## Coordinate-based meta-analysis\n",
    "\n",
    "NiMARE implements multiple coordinate-based meta-analysis methods, including ALE, MKDA chi-squared analysis, MKDA density analysis, and SCALE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meta-analytic Estimators are initialized with parameters which determine how the Estimator will be run. For example, ALE accepts a kernel transformer (which defaults to the standard `ALEKernel`), a null method, the number of iterations used to define the null distribution, and the number of cores to be used during fitting.\n",
    "\n",
    "The Estimators also have a `fit` method, which accepts a `Dataset` object and returns a `MetaResult` object. [`MetaResult`s](https://nimare.readthedocs.io/en/0.0.12/generated/nimare.results.MetaResult.html#nimare.results.MetaResult) link statistical image names to numpy arrays, and can be used to produce nibabel images from those arrays, as well as save the images to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = nimare.meta.cbma.ale.ALE(null_method=\"approximate\")\n",
    "meta_results = meta.fit(nimads_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(meta_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(meta_results.maps))\n",
    "print(\"Available maps:\")\n",
    "print(\"\\t- \" + \"\\n\\t- \".join(meta_results.maps.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_img = meta_results.get_map(\"z\")\n",
    "print(type(z_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    z_img,\n",
    "    draw_cross=False,\n",
    "    cut_coords=[0, 0, 0],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple comparisons correction\n",
    "\n",
    "Most of the time, you will want to follow up your meta-analysis with some form of multiple comparisons correction. For this, NiMARE provides Corrector classes in the `correct` module. Specifically, there are two Correctors: [`FWECorrector`](https://nimare.readthedocs.io/en/0.0.12/generated/nimare.correct.FWECorrector.html) and [`FDRCorrector`](https://nimare.readthedocs.io/en/0.0.12/generated/nimare.correct.FDRCorrector.html). In both cases, the Corrector supports a range of naive correction options that are not optimized for neuroimaging data, like Bonferroni correction.\n",
    "\n",
    "In addition to generic multiple comparisons correction, the Correctors also reference algorithm-specific correction methods, such as the `montecarlo` method supported by most coordinate-based meta-analysis algorithms.\n",
    "\n",
    "Correctors are initialized with parameters, and they have a `transform` method that accepts a `MetaResult` object and returns an updated one with the corrected maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_corrector = nimare.correct.FWECorrector(\n",
    "    method=\"montecarlo\",\n",
    "    n_iters=50,  # Use >=10000 for a real analysis\n",
    "    n_cores=1,\n",
    ")\n",
    "mc_results = mc_corrector.transform(meta_results)\n",
    "\n",
    "# Let's store the CBMA result for later\n",
    "cbma_z_img = mc_results.get_map(\"z_desc-size_level-cluster_corr-FWE_method-montecarlo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(mc_results.maps))\n",
    "print(\"Available maps:\")\n",
    "print(\"\\t- \" + \"\\n\\t- \".join(mc_results.maps.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    mc_results.get_map(\"z_desc-size_level-cluster_corr-FWE_method-montecarlo\"),\n",
    "    draw_cross=False,\n",
    "    cut_coords=[0, 0, 0],\n",
    "    vmax=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report a standard cluster table for the meta-analytic map using a threshold of p<0.05\n",
    "reporting.get_clusters_table(cbma_z_img, stat_threshold=1.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NiMARE also has diagnostic tools to characterize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus = nimare.diagnostics.FocusCounter(target_image=\"z_desc-size_level-cluster_corr-FWE_method-montecarlo\")\n",
    "focus_table, focus_img = focus.transform(mc_results)\n",
    "focus_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jackknife = nimare.diagnostics.Jackknife(target_image=\"z_desc-size_level-cluster_corr-FWE_method-montecarlo\")\n",
    "jackknife_table, jackknife_img = jackknife.transform(mc_results)\n",
    "jackknife_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image-based meta-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimads_dset.images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that \"z\" images are missing for some, but not all, of the studies.\n",
    "\n",
    "NiMARE's `transforms` module contains a class, `ImageTransformer`, which can generate images from other images- as long as the right images and metadata are available. In this case, it can generate z-statistic images from t-statistic maps, combined with sample size information in the metadata. It can also generate \"varcope\" (contrast variance) images from the contrast standard error images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing images\n",
    "# We want z and varcope (variance) images\n",
    "img_xformer = nimare.transforms.ImageTransformer(target=[\"z\", \"varcope\"], overwrite=False)\n",
    "nimads_dset = img_xformer.transform(nimads_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimads_dset.images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of the image types we will need for our meta-analyses, we can run a couple of image-based meta-analysis types.\n",
    "\n",
    "The `DerSimonianLaird` method uses \"beta\" and \"varcope\" images, and estimates between-study variance (a.k.a. $\\tau^2$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = nimare.meta.ibma.DerSimonianLaird(resample=True)\n",
    "meta_results = meta.fit(nimads_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    meta_results.get_map(\"z\"),\n",
    "    draw_cross=False,\n",
    "    cut_coords=[0, 0, 0],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PermutedOLS` method uses beta images, and relies on [nilearn's `permuted_ols`](https://nilearn.github.io/stable/modules/generated/nilearn.mass_univariate.permuted_ols.html) tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = nimare.meta.ibma.PermutedOLS(resample=True)\n",
    "meta.masker = nimads_dset.masker\n",
    "meta_results = meta.fit(nimads_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    meta_results.get_map(\"z\"),\n",
    "    draw_cross=False,\n",
    "    cut_coords=[0, 0, 0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_corrector = nimare.correct.FWECorrector(method=\"montecarlo\", n_iters=1000)\n",
    "mc_results = mc_corrector.transform(meta_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(mc_results.maps))\n",
    "print(\"Available maps:\")\n",
    "print(\"\\t- \" + \"\\n\\t- \".join(mc_results.maps.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    mc_results.get_map(\"z_level-voxel_corr-FWE_method-montecarlo\"),\n",
    "    draw_cross=False,\n",
    "    cut_coords=[0, 0, 0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report a standard cluster table for the meta-analytic map using a threshold of p<0.05\n",
    "reporting.get_clusters_table(\n",
    "    mc_results.get_map(\"z_level-voxel_corr-FWE_method-montecarlo\"),\n",
    "    stat_threshold=1.,\n",
    "    cluster_threshold=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    mc_results.get_map(\"z_level-voxel_corr-FWE_method-montecarlo\"),\n",
    "    threshold=1.65,\n",
    "    vmax=3,\n",
    "    draw_cross=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(\n",
    "    cbma_z_img,\n",
    "    threshold=1.65,\n",
    "    vmax=3,\n",
    "    draw_cross=False,\n",
    "    cut_coords=[0, 0, 0],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-Analytic Functional Decoding\n",
    "\n",
    "Functional decoding refers to approaches which attempt to infer mental processes, tasks, etc. from imaging data. There are many approaches to functional decoding, but one set of approaches uses meta-analytic databases like Neurosynth or BrainMap, which we call \"meta-analytic functional decoding.\" For more information on functional decoding in general, read [Poldrack (2011)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3240863/).\n",
    "\n",
    "In NiMARE, we group decoding methods into three general types: discrete decoding, continuous decoding, and encoding.\n",
    "\n",
    "- **Discrete decoding methods** use a meta-analytic database and annotations of studies in that database to describe something discrete (like a region of interest) in terms of those annotations.\n",
    "\n",
    "- **Continuous decoding methods** use the same type of database to describe an unthresholded brain map in terms of the database's annotations. One example of this kind of method is the Neurosynth-based decoding available on Neurovault. In that method, the map you want to decode is correlated with Neurosynth term-specific meta-analysis maps. You end up with one correlation coefficient for each term in Neurosynth. Users generally report the top ten or so terms.\n",
    "\n",
    "- **Encoding methods** do the opposite- they take in annotations or raw text and produce a synthesized brain map. One example of a meta-analytic encoding tool is [NeuroQuery](https://neuroquery.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the continuous decoding methods available in NiMARE are too computationally intensive and time-consuming for Binder, so we will focus on discrete decoding methods.\n",
    "The two most useful discrete decoders in NiMARE are the [`BrainMapDecoder`](https://nimare.readthedocs.io/en/0.0.12/generated/nimare.decode.discrete.BrainMapDecoder.html#nimare.decode.discrete.BrainMapDecoder) and the [`NeurosynthDecoder`](https://nimare.readthedocs.io/en/0.0.12/generated/nimare.decode.discrete.NeurosynthDecoder.html#nimare.decode.discrete.NeurosynthDecoder). Detailed descriptions of the two approaches are available in [NiMARE's documentation](https://nimare.readthedocs.io/en/0.0.12/decoding.html#discrete-decoding), but here's the basic idea:\n",
    "\n",
    "0. A NiMARE `Dataset` must contain both annotations/labels and coordinates.\n",
    "1. A subset of studies in the `Dataset` must be selected according to some criterion, such as having at least one peak in a region of interest or having a specific label.\n",
    "2. The algorithm then compares the frequency of each label within the selected subset of studies against the frequency of other labels in that subset to calculate \"forward-inference\" posterior probability, p-value, and z-statistic.\n",
    "3. The algorithm also compares the frequency of each label within the subset of studies against the the frequency of that label in the *unselected* studies from the `Dataset` to calculate \"reverse-inference\" posterior probability, p-value, and z-statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ids = neurosynth_dset.get_studies_by_label(\"terms_abstract_tfidf__amygdala\", label_threshold=0.001)\n",
    "print(f\"There are {len(label_ids)} studies in the Dataset with the 'Neurosynth_TFIDF__amygdala' label.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = nimare.decode.discrete.BrainMapDecoder(correction=None)\n",
    "decoder.fit(neurosynth_dset)\n",
    "decoded_df = decoder.transform(ids=label_ids)\n",
    "decoded_df.sort_values(by=\"probReverse\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = nimare.decode.discrete.NeurosynthDecoder(correction=None)\n",
    "decoder.fit(neurosynth_dset)\n",
    "decoded_df = decoder.transform(ids=label_ids)\n",
    "decoded_df.sort_values(by=\"probReverse\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NiMARE and the NeuroStore Ecosystem\n",
    "\n",
    "We are working on an online repository of both coordinates and images, drawn from Neurosynth, NeuroQuery, and NeuroVault. This repository will include the ability to curate collections of studies, annotate them, and run meta-analyses on them with NiMARE.\n",
    "\n",
    "![NeuroStore Ecosystem](images/ecosystem.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Run a MACM and Decode an ROI\n",
    "\n",
    "Remember that a MACM is a meta-analysis performed on studies which report at least one peak within a region of interest. This type of analysis is generally interpreted as a meta-analytic version of functional connectivity analysis.\n",
    "\n",
    "We will use an amygdala mask as our ROI, which we will use to (1) run a MACM using the (reduced) Neurosynth dataset and (2) decode the ROI using labels from Neurosynth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to prepare some things for the exercise. You just need to run these cells without editing anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_FILE = os.path.join(DATA_DIR, \"amygdala_roi.nii.gz\")\n",
    "\n",
    "plotting.plot_roi(\n",
    "    ROI_FILE,\n",
    "    title=\"Right Amygdala\",\n",
    "    draw_cross=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, try to write code in each cell based on its comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, use the Dataset class's get_studies_by_mask method\n",
    "# to identify studies with at least one coordinate in the ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, create a reduced version of the Dataset including only\n",
    "# studies identified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, run a meta-analysis on the reduced ROI dataset.\n",
    "# This is a MACM.\n",
    "# Use the nimare.meta.cbma.MKDADensity meta-analytic estimator.\n",
    "# Do not perform multiple comparisons correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize, fit, and transform a Neurosynth Decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After the exercise\n",
    "\n",
    "Your MACM results should look something like this:\n",
    "\n",
    "![MACM Results](images/macm_result.png)\n",
    "\n",
    "And your decoding results should look something like this, after sorting by probReverse:\n",
    "\n",
    "| Term                            |     pForward |   zForward |   probForward |    pReverse |   zReverse |   probReverse |\n",
    "|:--------------------------------|-------------:|-----------:|--------------:|------------:|-----------:|--------------:|\n",
    "| Neurosynth_TFIDF__amygdala      | 4.14379e-113 |  22.602    |      0.2455   | 1.17242e-30 |   11.5102  |      0.964733 |\n",
    "| Neurosynth_TFIDF__reinforcement | 7.71236e-05  |   3.95317  |      0.522177 | 7.35753e-15 |    7.77818 |      0.957529 |\n",
    "| Neurosynth_TFIDF__olfactory     | 0.0147123    |   2.43938  |      0.523139 | 5.84089e-11 |    6.54775 |      0.955769 |\n",
    "| Neurosynth_TFIDF__fear          | 1.52214e-11  |   6.74577  |      0.448855 | 6.41482e-19 |    8.88461 |      0.95481  |\n",
    "| Neurosynth_TFIDF__age sex       | 0.503406     |   0.669141 |      0.524096 | 3.8618e-07  |    5.07565 |      0.954023 |\n",
    "| Neurosynth_TFIDF__appraisal     | 0.503406     |   0.669141 |      0.524096 | 3.8618e-07  |    5.07565 |      0.954023 |\n",
    "| Neurosynth_TFIDF__apart         | 0.503406     |   0.669141 |      0.524096 | 3.8618e-07  |    5.07565 |      0.954023 |\n",
    "| Neurosynth_TFIDF__naturalistic  | 0.555471     |   0.589582 |      0.52505  | 0.00122738  |    3.23244 |      0.95229  |\n",
    "| Neurosynth_TFIDF__controls hc   | 0.555471     |   0.589582 |      0.52505  | 0.00122738  |    3.23244 |      0.95229  |\n",
    "| Neurosynth_TFIDF__morphology    | 0.555471     |   0.589582 |      0.52505  | 0.00122738  |    3.23244 |      0.95229  |"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
